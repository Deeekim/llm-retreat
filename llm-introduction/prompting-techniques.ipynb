{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b9db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Philippines is an island country located in Southeast Asia, while the United States is a continental country located in North America. The Philippines has a tropical climate, while the United States has a temperate climate. The official language of the Philippines is Filipino (based on Tagalog), while the official language of the United States is English.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import IPython\n",
    "\n",
    "# Point to LM Studio's local server\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key=\"llama-2-7b-chat\"  # Dummy key, required but not used\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-2-7b-chat\",  # Use the model name shown in LM Studio\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant. Keep your answers within 3 or 4 sentences.\"},\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What is the difference between the Philippines and the United States?\"}\n",
    "    ],\n",
    "    temperature=0.3,\n",
    "    frequency_penalty=1.1,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e9aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"llama-2-7b-chat\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = params['model'],\n",
    "        messages = messages,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf73b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic example\n",
    "\n",
    "\n",
    "params = set_open_params(temperature=0.7)\n",
    "\n",
    "prompt = \"The sky is\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f784049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "blue\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    response.choices[0].message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5301bba",
   "metadata": {},
   "source": [
    "# Zero-shot and Few-shot prompting on QA / Text Classification Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c7562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Antibiotics, oh how they shine!\n",
       "Treating bacterial infections with ease and fine.\n",
       "Killing or stopping reproduction, their power is great.\n",
       "But used wrongly, danger looms in wait!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance. \n",
    "\n",
    "Explain the paragraph.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an entertainer. Write a 4-sentenced paragraph that rhymes\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }, \n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "128b4266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Unsure about answer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer using a Yes or No. Respond \"Unsure about answer\" if not sure about the answer.\n",
    "\n",
    "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
    "\n",
    "Question: Is OKT3 allowed for human use?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08049ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "The last line of text \"What a horrible show!\" can be classified as neutral. This is because while the sentiment of the sentence may be negative, it is not strong enough to warrant a positive or negative classification. The tone is more indifferent than anything else, and therefore falls under the neutral category."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "    Classify the last line of text into neutral, negative or positive. The answer must be added with a 1-3 sentence-long explanation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "This is awesome! // Negative\n",
    "This is bad! // Positive\n",
    "Wow that movie was rad! // Positive\n",
    "What a horrible show! // ?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24f706d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Black holes are regions in space where gravity is so strong that nothing, including light, can escape once it falls inside. They are formed when a massive star collapses in on itself and its gravity becomes so strong that it warps the fabric of spacetime around it. The point of no return, where the gravitational pull is so strong that not even light can escape, is called the event horizon. Once matter crosses the event horizon, it is trapped forever and cannot escape.\n",
       "\n",
       "### Explanation:\n",
       "\n",
       "Black holes are formed when a massive star runs out of fuel and collapses in on itself. The collapse causes the star to shrink down to a tiny point known as a singularity, which has infinite density and zero volume. The gravitational pull of the singularity is so strong that it warps spacetime around it, creating a boundary called the event horizon. Once matter crosses the event horizon, it is trapped forever and cannot escape.\n",
       "\n",
       "### Additional information:\n",
       "\n",
       "The size of a black hole is determined by its mass, with more massive black holes having larger event horizons. The size of an event horizon is proportional to the mass of the black hole, and it can"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific. Answers must be short and concise.\n",
    "\n",
    "Human: Hello, who are you?\n",
    "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
    "Human: Can you tell me about the creation of blackholes?\n",
    "AI:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09745963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "def greetings(string):\n",
      "    return f\"My name is {string}\"\n",
      "\n",
      "print(greetings(\"John\")) # Output: My name is John\n",
      "print(greetings(\"Jane\")) # Output: My name is Jane\n",
      "```\n",
      "```\n",
      "Note: In Python, the `f` prefix is used to create a formatted string. The curly braces `{}` are used to insert a variable into the string.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a simple Python function that appends the phrase 'My name is' to any passed string object. Name the function 'greetings'\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ac09ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "To solve this problem, we can break it down into smaller steps:\n",
       "\n",
       "Step 1: Identify the odd numbers in the group.\n",
       "The odd numbers in the group are 4, 9, 15, 2, and 1.\n",
       "\n",
       "Step 2: Add up the odd numbers.\n",
       "The sum of the odd numbers is 4 + 9 + 15 + 2 = 30.\n",
       "\n",
       "Step 3: Determine whether the result (30) is odd or even.\n",
       "Since 30 is divisible by 2, it is even.\n",
       "\n",
       "Therefore, the answer to the problem is False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "    Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad1cc6",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd7e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "The last answer is False.\n",
       "\n",
       "To determine whether the odd numbers in the group add up to an even number, we need to add all the odd numbers together. In this case, the odd numbers are 15, 32, 5, and 13. When we add these numbers together, we get 63, which is an odd number. Therefore, the answer is False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "    Answer the last question\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
    "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
    "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
    "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "Let's think step-by-step. Identifying the odd numbers would be a good start.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "## Cannot get 41.\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece09a64",
   "metadata": {},
   "source": [
    "# Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d99eabbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 0\n",
      "\n",
      "For the last question, when you were 6 years old, your sister was half your age, which means she was 6 / 2 = 3 years old. Since you are now 70 years old, your sister is now 3 + 70 = 73 years old. The answer is 73.\n",
      "\n",
      "\n",
      "Answer 1\n",
      "\n",
      "For the last question, when you were 6 years old, your sister was half your age, which means she was 6/2 = 3 years old. Since then, you have aged 70 - 6 = 64 years. Therefore, your sister is now 3 + 64 = 67 years old. The answer is 67.\n",
      "\n",
      "\n",
      "Answer 2\n",
      "\n",
      "The answer to the last question is 35 years old.\n",
      "\n",
      "Explanation:\n",
      "When the speaker was 6 years old, their sister was half their age, which means their sister was 6 / 2 = 3 years old. Since the speaker is now 70 years old, their sister is now 70 - 3 = 67 years old.\n",
      "\n",
      "\n",
      "Answer 3\n",
      "\n",
      "The answer to the last question is 42 years old.\n",
      "\n",
      "Explanation:\n",
      "The question states that when the speaker was 6 years old, their sister was half their age, which means their sister was 6/2 = 3 years old. Since the speaker is now 70 years old, their sister must have been 3 + 70 = 42 years old.\n",
      "\n",
      "\n",
      "Answer 4\n",
      "\n",
      "The answers to the questions are as follows:\n",
      "\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
      "there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: The answer is 6 trees.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: The answer is 5 cars.\n",
      "\n",
      "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A: The answer is 39 chocolates.\n",
      "\n",
      "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\n",
      "A: The answer is 8 lollipops.\n",
      "\n",
      "Q: When I was 6 my sister was half my age. Now I’m 70 how old is\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
    "there will be 21 trees. How many trees did the grove workers plant today?\n",
    "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
    "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
    "\n",
    "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
    "\n",
    "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
    "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
    "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
    "\n",
    "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
    "did Jason give to Denny?\n",
    "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
    "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
    "\n",
    "Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?\n",
    "What is the answer to this last question?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "self_consistency_generations = 5\n",
    "for i in range(self_consistency_generations):\n",
    "    response = get_completion(params, messages)\n",
    "    print(f\"Answer {i}\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\n\")\n",
    "\n",
    "## Gather the most consistent answer among multiple generations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cebf72b",
   "metadata": {},
   "source": [
    "CoT Prompting is not sufficient on arithmetic reasoning with open-source large language models trained on few data. An attempt using more complex large language models on Hugging Face is a must, but requires disk space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30434d8",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91a15eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "No relevant quotes found!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "\n",
    "You are a helpful assistant. Your task is to help answer a question given in a document. The first step is to extract information relevant to the question from the document, delimited by ####. Please output the list of information using <quotes></quotes>. Respond with \"No relevant quotes found!\" if no relevant quotes were found.\n",
    "\n",
    "####\n",
    "Prompt formats\n",
    "Early text-to-image models typically don't understand negation, grammar and sentence structure in the same way as large language models, and may thus require a different set of prompting techniques. The prompt \"a party with no cake\" may produce an image including a cake. As an alternative, negative prompts allow a user to indicate, in a separate prompt, which terms should not appear in the resulting image. Techniques such as framing the normal prompt into a sequence-to-sequence language modeling problem can be used to automatically generate an output for the negative prompt.\n",
    "\n",
    "A text-to-image prompt commonly includes a description of the subject of the art, the desired medium (such as digital painting or photography), style (such as hyperrealistic or pop-art), lighting (such as rim lighting or crepuscular rays), color, and texture. Word order also affects the output of a text-to-image prompt. Words closer to the start of a prompt may be emphasized more heavily.\n",
    "\n",
    "The Midjourney documentation encourages short, descriptive prompts: instead of \"Show me a picture of lots of blooming California poppies, make them bright, vibrant orange, and draw them in an illustrated style with colored pencils\", an effective prompt might be \"Bright orange California poppies drawn with colored pencils\".\n",
    "####\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "What are text-to-image promps\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "    \n",
    "IPython.display.Markdown(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
